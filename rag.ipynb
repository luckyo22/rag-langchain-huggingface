{"cells":[{"cell_type":"markdown","metadata":{"id":"LmngfLnhzimH"},"source":["# Environment Setup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oMuVUKi3zimL"},"outputs":[],"source":["! pip install -q langchain_community tiktoken langchainhub chromadb langchain sentence-transformers huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Nwd6diFzimO"},"outputs":[],"source":["import os\n","\n","huggingface_api_token = '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'\n","\n","os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n","os.environ['LANGCHAIN_API_KEY'] = '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'\n","os.environ['HUGGINGFACEHUB_API_TOKEN'] = huggingface_api_token"]},{"cell_type":"markdown","metadata":{"id":"dQBuvEjWzimO"},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVeUE8oVzimP"},"outputs":[],"source":["import bs4\n","from langchain import hub\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.document_loaders import WebBaseLoader\n","from langchain_community.vectorstores import Chroma\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain.prompts import ChatPromptTemplate\n","from langchain.chains import LLMChain\n","from langchain_core.prompts import PromptTemplate\n","from langchain_community.llms import HuggingFaceEndpoint\n","from langchain_community.embeddings.sentence_transformer import (\n","    SentenceTransformerEmbeddings,\n",")"]},{"cell_type":"markdown","metadata":{"id":"nK08gM0_zimP"},"source":["# Indexing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWOngiJYzimQ"},"outputs":[],"source":["# Load documents\n","loader = WebBaseLoader(\n","    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n","    bs_kwargs=dict(\n","        parse_only=bs4.SoupStrainer(\n","            class_=(\"post-content\", \"post-title\", \"post-header\")\n","        )\n","    ),\n",")\n","\n","docs = loader.load()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNQTLzAGzimQ"},"outputs":[],"source":["# Split\n","text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=300, chunk_overlap=50)\n","\n","splits = text_splitter.split_documents(docs)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S1ln-juWzimR"},"outputs":[],"source":["# Embed\n","\n","vectorstore = Chroma.from_documents(documents=splits, embedding=SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\"))\n"]},{"cell_type":"markdown","metadata":{"id":"7wtGNnSNzimR"},"source":["# Retrieval"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gEplUu_mzimS"},"outputs":[],"source":["retriever = vectorstore.as_retriever(search_kwargs={\"k\":1})\n","\n","docs = retriever.get_relevant_documents(\"What is Self-Reflection?\")"]},{"cell_type":"markdown","metadata":{"id":"iaZHvMpDzimS"},"source":["# Generation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KJqoyZp9zimS"},"outputs":[],"source":["# Prompt\n","template = \"\"\" Answer the question based only on the following context:\n","{context}\n","\n","Question: {question}\n","\"\"\"\n","\n","prompt = ChatPromptTemplate.from_template(template=template)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YShP-wNyzimS","outputId":"ecdb4fb7-6bb7-4963-e200-536cf82025f6"},"outputs":[{"data":{"text/plain":["ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template=' Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'))])"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNySpPQhzimT"},"outputs":[],"source":["# LLM\n","repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","\n","llm = HuggingFaceEndpoint(\n","    repo_id=repo_id, max_length=128, temperature=0.5, token=huggingface_api_token\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4om5Y3eEzimT"},"outputs":[],"source":["# Chain\n","chain = prompt | llm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lzFP4czbzimT","outputId":"228584ba-9253-43c5-de13-f3ad4c8dff18"},"outputs":[{"data":{"text/plain":["\"\\nAnswer: In the context of the Reflexion framework discussed in the document, Self-Reflection refers to a mechanism where an agent learns from its past mistakes by being shown pairs of a failed trajectory and an ideal reflection. These reflections are then stored in the agent's working memory for use as context when querying the Large Language Model (LLM) to guide future changes in the plan.\""]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["# Run\n","chain.invoke({\"context\":docs,\"question\":\"What is Self-Reflection?\"})\n"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}